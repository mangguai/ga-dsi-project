{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone Project - TheiaVision: Object Detection Technology for PMD Safety Alerts\n",
    "\n",
    "> Authors: Ng Wei\n",
    "---\n",
    "\n",
    "**Problem Statement:**  \n",
    "How can we enhance the safety of Personal Mobility Devices (PMDs) in urban environments by using object detection to improve PMD users' ability to perceive and respond to their surroundings?\n",
    "\n",
    "**Target Audience:**\n",
    "Management Team of PMD Maker\n",
    "\n",
    "**Summary:**\n",
    "This project aims to develop a object detection system to identifies obstacles such as pedestrians, vehicles, and traffic signs. By leveraging CNN algorithms YOLO model, this system would help Darren, a project manager, to lead the development of an alert system with object detection technology\n",
    "\n",
    "There are a total of three notebooks for this project:  \n",
    " 1. `01_EDA.ipynb`   \n",
    " 2. `02_Modelling_Pytorch_SimpleCNN_SGTrafficSign.ipynb`   \n",
    " 3. `03_Modelling_YOLOv8_labeled_SGTrafficSign.ipynb`\n",
    " 4. `04_Merge_MultiDataset.ipynb`\n",
    " 5. `05_Modelling_YOLOv8_combined_data.ipynb`\n",
    " 6. `06_YOLOv8_Hyperparameter_Tuning.ipynb`\n",
    "\n",
    "---\n",
    "**This Notebook**\n",
    "- We will train the YOLOv8 model with merged dataset `Master_dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 YOLOv8 Modelling with `Master_Dataset`\n",
    "\n",
    "The dataset has been successfully prepared and split into training, validation, and testing sets. This includes ensuring a balanced distribution of classes across all sets, especially with a focus on rare class representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the classes and their corresponding indices\n",
    "class_names = [\n",
    "    'curveleft_sign',           # Class 0\n",
    "    'curveright_sign',          # Class 1\n",
    "    'mandatorystop_sign',       # Class 2\n",
    "    'noentry_sign',             # Class 3\n",
    "    'nojaywalking_sign',        # Class 4\n",
    "    'pedestriancrossing_sign',  # Class 5\n",
    "    'zebracrossing_sign',       # Class 6\n",
    "    'biker',                    # Class 7\n",
    "    'car',                      # Class 8\n",
    "    'pedestrian',               # Class 9\n",
    "    'trafficlight',             # Class 10\n",
    "    'trafficlight_green',       # Class 11\n",
    "    'trafficlight_red',         # Class 12\n",
    "    'trafficlight_yellow',      # Class 13\n",
    "    'truck'                     # Class 14\n",
    "]\n",
    "class_indices = {name: index for index, name in enumerate(class_names)}\n",
    "\n",
    "# Image dimensions\n",
    "img_width, img_height = 640, 640\n",
    "\n",
    "# Path to the folder containing the annotation files\n",
    "folder_path = 'Master_Dataset/train/labels'\n",
    "output_folder_path = 'Master_Dataset/train/modified_labels'  # New output folder\n",
    "\n",
    "os.makedirs(output_folder_path, exist_ok=True)  # Ensure the output directory exists\n",
    "\n",
    "# Function to normalize coordinates\n",
    "def normalize_coordinates(x, y, w, h, img_width, img_height):\n",
    "    dw = 1.0 / img_width\n",
    "    dh = 1.0 / img_height\n",
    "    x_center = (x + w / 2.0) * dw\n",
    "    y_center = (y + h / 2.0) * dh\n",
    "    width = w * dw\n",
    "    height = h * dh\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "# Process each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):  # assuming the annotation files are .txt files\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        output_file_path = os.path.join(output_folder_path, filename)  # Output file path\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:  # Ensure this is a YOLO format line\n",
    "                class_index, x, y, w, h = map(float, parts)\n",
    "                # Normalize coordinates\n",
    "                x_center, y_center, width, height = normalize_coordinates(x, y, w, h, img_width, img_height)\n",
    "                new_line = f\"{int(class_index)} {x_center} {y_center} {width} {height}\"\n",
    "                new_lines.append(new_line)\n",
    "\n",
    "        # Write the converted lines to a new file in the output directory\n",
    "        with open(output_file_path, 'w') as file:\n",
    "            file.write('\\n'.join(new_lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1 Model Training Execution Using YOLOv8\n",
    "\n",
    "### 5.1.1.1 Overview\n",
    "This script automates the process of training a YOLOv8 model using the `subprocess` module in Python. The training configuration specifies the model, dataset, number of epochs, image size, and batch size.\n",
    "\n",
    "### 5.1.1.2 Script Details\n",
    "- **Model:** `yolov8s.pt`\n",
    "- **Dataset:** Specified in `data.yaml` located at `/home/mangguai/capstone/code/Master_Dataset/`\n",
    "- **Epochs:** 20\n",
    "- **Image Size:** 640x640 pixels\n",
    "- **Batch Size:** 8\n",
    "\n",
    "### 5.1.1.3 Command Execution\n",
    "The training command is executed in the system's shell using `subprocess.run`. This method allows the script to initiate the YOLO model training directly from the Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.10 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.11.8 torch-2.2.2 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/home/mangguai/capstone/code/Master_Dataset/data.yaml, epochs=20, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2121853  ultralytics.nn.modules.head.Detect           [15, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11141405 parameters, 11141389 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/mangguai/capstone/code/Master_Dataset/train/labels.cache... 20769 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20769/20769 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/mangguai/capstone/code/Master_Dataset/train/images/1478021875081281646_jpg.rf.e9552980cf8c6fef4aa02cb84c6364f5.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/mangguai/capstone/code/Master_Dataset/train/images/1478898145212453716_jpg.rf.6a92d7d7dd523160c990c4e4375bcea9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/mangguai/capstone/code/Master_Dataset/train/images/1478898145212453716_jpg.rf.nCaFkPk4AFMjTQAM4RTJ.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/mangguai/capstone/code/Master_Dataset/valid/labels.cache... 5430 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5430/5430 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/mangguai/capstone/code/Master_Dataset/valid/images/1478897760163798179_jpg.rf.98623be50b02ff17d58f89fddf7a0c6c.jpg: 1 duplicate labels removed\n",
      "Plotting labels to runs/detect/train4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/20      2.46G      1.459      1.292      1.168          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:50<00:00,  7.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:52<00:00,  6.51it/s]\n",
      "                   all       5430      39476      0.636      0.649      0.652      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/20      2.58G      1.411      0.937      1.156          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:36<00:00,  7.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:58<00:00,  5.86it/s]\n",
      "                   all       5430      39476      0.649      0.713      0.683      0.425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/20      2.58G      1.397     0.9078       1.15          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:42<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:51<00:00,  6.57it/s]\n",
      "                   all       5430      39476      0.737      0.725      0.704        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/20      2.57G      1.381     0.8814      1.142         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:43<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:54<00:00,  6.18it/s]\n",
      "                   all       5430      39476      0.708      0.736      0.725      0.522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/20      2.56G      1.361     0.8521       1.13         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:34<00:00,  7.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:56<00:00,  6.01it/s]\n",
      "                   all       5430      39476      0.759      0.733      0.732      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/20      2.57G      1.338      0.828      1.122          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:43<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:55<00:00,  6.08it/s]\n",
      "                   all       5430      39476      0.763      0.759       0.75       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/20      2.56G      1.327     0.8092      1.115          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:43<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:48<00:00,  6.99it/s]\n",
      "                   all       5430      39476      0.787       0.76      0.754      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/20      2.57G      1.307      0.789      1.105          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:43<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:54<00:00,  6.23it/s]\n",
      "                   all       5430      39476      0.787      0.772      0.783      0.568\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/20      2.56G      1.288     0.7684      1.099          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:34<00:00,  7.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:57<00:00,  5.88it/s]\n",
      "                   all       5430      39476      0.784      0.772      0.767      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/20      2.57G      1.275     0.7531      1.089          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:41<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:58<00:00,  5.81it/s]\n",
      "                   all       5430      39476      0.803      0.773      0.772      0.558\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/20      2.56G      1.315     0.7311      1.104         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:34<00:00,  7.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:57<00:00,  5.88it/s]\n",
      "                   all       5430      39476      0.805      0.783      0.783      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/20      2.56G      1.294     0.7073      1.095          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:42<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:56<00:00,  6.07it/s]\n",
      "                   all       5430      39476      0.819      0.778      0.799      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/20      2.55G      1.277     0.6903      1.086          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:42<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:58<00:00,  5.77it/s]\n",
      "                   all       5430      39476       0.81      0.792      0.794      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/20      2.56G      1.258     0.6725      1.079          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:38<00:00,  7.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:57<00:00,  5.90it/s]\n",
      "                   all       5430      39476      0.817      0.794      0.826      0.619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/20      2.56G      1.239     0.6567      1.073          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:30<00:00,  7.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:52<00:00,  6.50it/s]\n",
      "                   all       5430      39476      0.831      0.792      0.825      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/20      2.56G      1.222     0.6426      1.067          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:41<00:00,  7.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:56<00:00,  6.04it/s]\n",
      "                   all       5430      39476      0.822      0.809       0.82      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/20      2.55G      1.204     0.6264      1.058          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:35<00:00,  7.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:52<00:00,  6.47it/s]\n",
      "                   all       5430      39476      0.825      0.812      0.839      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/20      2.56G      1.191     0.6127      1.051         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:27<00:00,  7.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:53<00:00,  6.30it/s]\n",
      "                   all       5430      39476      0.821      0.802      0.851      0.652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/20      2.56G      1.171      0.602      1.042          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [06:43<00:00,  6.43it/s]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:56<00:00,  5.96it/s]\n",
      "                   all       5430      39476      0.847      0.799       0.86      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/20      2.56G      1.156     0.5907      1.037          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:29<00:00,  7.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:53<00:00,  6.33it/s]\n",
      "                   all       5430      39476      0.845      0.809      0.862       0.66\n",
      "\n",
      "20 epochs completed in 2.214 hours.\n",
      "Optimizer stripped from runs/detect/train4/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train4/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train4/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.11.8 torch-2.2.2 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 168 layers, 11131389 parameters, 0 gradients, 28.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [01:03<00:00,  5.35it/s]\n",
      "                   all       5430      39476      0.845      0.809      0.862       0.66\n",
      "     nojaywalking_sign       5430          6      0.309          1      0.894      0.838\n",
      "    mandatorystop_sign       5430         14      0.698          1      0.933      0.881\n",
      "       curveright_sign       5430         19      0.938          1      0.993      0.918\n",
      "    zebracrossing_sign       5430         26      0.934      0.962      0.971      0.865\n",
      "          noentry_sign       5430         47      0.983      0.936      0.979      0.945\n",
      "pedestriancrossing_sign       5430         33      0.963      0.786      0.899      0.825\n",
      "        curveleft_sign       5430         33      0.982          1      0.995       0.93\n",
      "                 biker       5430        765      0.792      0.633      0.702      0.399\n",
      "                   car       5430      25812      0.891      0.805      0.865       0.59\n",
      "            pedestrian       5430       4114       0.84      0.563      0.688      0.359\n",
      "          trafficlight       5430       1038      0.859      0.808      0.868      0.556\n",
      "    trafficlight_green       5430       2283      0.855      0.651      0.748      0.365\n",
      "      trafficlight_red       5430       3718      0.924       0.73      0.842      0.506\n",
      "   trafficlight_yellow       5430        115      0.872      0.443      0.674      0.293\n",
      "                 truck       5430       1453      0.834      0.822      0.879      0.626\n",
      "Speed: 0.2ms preprocess, 3.4ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='yolo train model=yolov8s.pt data=/home/mangguai/capstone/code/Master_Dataset/data.yaml epochs=20 imgsz=640 batch=8', returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Command to run\n",
    "command = \"yolo train model=yolov8s.pt data=/home/mangguai/capstone/code/Master_Dataset/data.yaml epochs=20 imgsz=640 batch=8\"\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(command, shell=True)\n",
    "\n",
    "#134min for 20 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The YOLOv8 model completed 20 epochs of training on the dataset with 39,476 instances across 5,430 images, achieving a final mAP50 of 0.862 and mAP50-95 of 0.66, demonstrating strong performance especially in identifying traffic-related signs and objects. The entire training process took approximately 2.214 hours, effectively utilizing the capabilities of an NVIDIA GeForce RTX 3060 Laptop GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.10 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.11.8 torch-2.2.2 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/home/mangguai/capstone/code/Master_Dataset/data.yaml, epochs=25, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n",
      "Overriding model.yaml nc=80 with nc=15\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2121853  ultralytics.nn.modules.head.Detect           [15, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11141405 parameters, 11141389 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train5', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/mangguai/capstone/code/Master_Dataset/train/labels.cache... 20769 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20769/20769 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/mangguai/capstone/code/Master_Dataset/train/images/1478021875081281646_jpg.rf.e9552980cf8c6fef4aa02cb84c6364f5.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/mangguai/capstone/code/Master_Dataset/train/images/1478898145212453716_jpg.rf.6a92d7d7dd523160c990c4e4375bcea9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/mangguai/capstone/code/Master_Dataset/train/images/1478898145212453716_jpg.rf.nCaFkPk4AFMjTQAM4RTJ.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/mangguai/capstone/code/Master_Dataset/valid/labels.cache... 5430 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5430/5430 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/mangguai/capstone/code/Master_Dataset/valid/images/1478897760163798179_jpg.rf.98623be50b02ff17d58f89fddf7a0c6c.jpg: 1 duplicate labels removed\n",
      "Plotting labels to runs/detect/train5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train5\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/25      2.46G      1.459      1.292      1.168          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:55<00:00,  7.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:53<00:00,  6.36it/s]\n",
      "                   all       5430      39476      0.636      0.649      0.652      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/25      2.58G      1.412     0.9391      1.156          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:42<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [01:03<00:00,  5.35it/s]\n",
      "                   all       5430      39476      0.604      0.721       0.67      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/25      2.57G        1.4     0.9139       1.15          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:37<00:00,  7.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:56<00:00,  6.07it/s]\n",
      "                   all       5430      39476      0.685      0.729      0.714      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/25      2.57G      1.383     0.8847      1.141         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:38<00:00,  7.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:52<00:00,  6.44it/s]\n",
      "                   all       5430      39476      0.751      0.738      0.717      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/25      2.56G      1.363     0.8556      1.135         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:35<00:00,  7.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:58<00:00,  5.79it/s]\n",
      "                   all       5430      39476      0.784        0.7      0.747      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/25      2.57G      1.344     0.8335      1.126          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:33<00:00,  7.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:59<00:00,  5.71it/s]\n",
      "                   all       5430      39476      0.763      0.754      0.741      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/25      2.57G       1.33     0.8146      1.118          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:44<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:56<00:00,  6.00it/s]\n",
      "                   all       5430      39476       0.79      0.754      0.741      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/25      2.57G      1.313     0.7945      1.107          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:40<00:00,  7.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [01:02<00:00,  5.44it/s]\n",
      "                   all       5430      39476       0.79      0.762      0.763      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/25      2.57G      1.296     0.7761      1.102          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:32<00:00,  7.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:57<00:00,  5.89it/s]\n",
      "                   all       5430      39476      0.792      0.769      0.766      0.558\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/25      2.57G      1.282     0.7606      1.093          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:32<00:00,  7.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:55<00:00,  6.10it/s]\n",
      "                   all       5430      39476      0.784       0.77      0.763      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/25      2.56G      1.273     0.7494      1.091          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:31<00:00,  7.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [01:00<00:00,  5.66it/s]\n",
      "                   all       5430      39476      0.819      0.766      0.787       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/25      2.56G       1.26     0.7377      1.085          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:32<00:00,  7.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:57<00:00,  5.95it/s]\n",
      "                   all       5430      39476      0.798      0.782      0.788      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/25      2.55G      1.249     0.7221      1.078         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:28<00:00,  7.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:53<00:00,  6.38it/s]\n",
      "                   all       5430      39476      0.796      0.789      0.786      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/25      2.57G      1.236     0.7101      1.072          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:12<00:00,  8.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:51<00:00,  6.66it/s]\n",
      "                   all       5430      39476      0.794      0.798      0.798      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/25      2.56G      1.227     0.7007       1.07         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:35<00:00,  7.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:58<00:00,  5.78it/s]\n",
      "                   all       5430      39476        0.8      0.795      0.807      0.599\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/25      2.57G      1.262     0.6777      1.082          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:43<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [01:01<00:00,  5.51it/s]\n",
      "                   all       5430      39476      0.811      0.793      0.801      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/25      2.56G      1.241     0.6573      1.074          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:35<00:00,  7.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:56<00:00,  6.02it/s]\n",
      "                   all       5430      39476      0.807      0.794      0.803      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/25      2.57G      1.226     0.6432      1.065         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:43<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:58<00:00,  5.82it/s]\n",
      "                   all       5430      39476      0.816      0.808      0.815      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/25      2.56G      1.211     0.6336      1.058          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:38<00:00,  7.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:58<00:00,  5.82it/s]\n",
      "                   all       5430      39476      0.819      0.809      0.822      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/25      2.57G      1.195     0.6197      1.053          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:35<00:00,  7.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:57<00:00,  5.91it/s]\n",
      "                   all       5430      39476      0.832        0.8      0.817      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/25      2.54G       1.18      0.607      1.046          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:32<00:00,  7.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:59<00:00,  5.68it/s]\n",
      "                   all       5430      39476       0.83      0.814      0.825      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/25      2.56G      1.167     0.5959      1.043          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:26<00:00,  7.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:56<00:00,  5.97it/s]\n",
      "                   all       5430      39476      0.857      0.789      0.842      0.639\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/25      2.55G      1.152     0.5855      1.036          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:20<00:00,  8.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:52<00:00,  6.47it/s]\n",
      "                   all       5430      39476      0.823      0.819      0.837      0.636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/25      2.56G      1.141     0.5761      1.031         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:24<00:00,  8.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:55<00:00,  6.07it/s]\n",
      "                   all       5430      39476      0.843      0.806      0.839       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/25      2.55G      1.127     0.5677      1.026         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2597/2597 [05:26<00:00,  7.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:56<00:00,  6.02it/s]\n",
      "                   all       5430      39476      0.855      0.805      0.867      0.668\n",
      "\n",
      "25 epochs completed in 2.729 hours.\n",
      "Optimizer stripped from runs/detect/train5/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train5/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train5/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.11.8 torch-2.2.2 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 168 layers, 11131389 parameters, 0 gradients, 28.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [01:08<00:00,  4.93it/s]\n",
      "                   all       5430      39476      0.857      0.804      0.867      0.669\n",
      "        curveleft_sign       5430          6      0.346          1      0.866       0.85\n",
      "       curveright_sign       5430         14      0.791          1      0.967      0.911\n",
      "    mandatorystop_sign       5430         19      0.932      0.947      0.963        0.9\n",
      "          noentry_sign       5430         26      0.942      0.962      0.967      0.842\n",
      "     nojaywalking_sign       5430         47      0.984      0.936      0.972      0.932\n",
      "pedestriancrossing_sign       5430         33      0.849      0.854       0.94      0.878\n",
      "    zebracrossing_sign       5430         33      0.984          1      0.995      0.931\n",
      "                 biker       5430        765      0.829      0.604      0.719      0.415\n",
      "                   car       5430      25812      0.902      0.802      0.868      0.598\n",
      "            pedestrian       5430       4114      0.865      0.545      0.702      0.368\n",
      "          trafficlight       5430       1038      0.866      0.801      0.874      0.563\n",
      "    trafficlight_green       5430       2283       0.87      0.631      0.759       0.38\n",
      "      trafficlight_red       5430       3718      0.931      0.733      0.845      0.514\n",
      "   trafficlight_yellow       5430        115      0.873      0.443       0.68      0.313\n",
      "                 truck       5430       1453       0.89      0.803      0.889      0.641\n",
      "Speed: 0.2ms preprocess, 3.4ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train5\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='yolo train model=yolov8s.pt data=/home/mangguai/capstone/code/Master_Dataset/data.yaml epochs=25 imgsz=640 batch=8', returncode=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Command to run\n",
    "command = \"yolo train model=yolov8s.pt data=/home/mangguai/capstone/code/Master_Dataset/data.yaml epochs=25 imgsz=640 batch=8\"\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(command, shell=True)\n",
    "\n",
    "#165min for 25 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.11.8 torch-2.2.2 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 168 layers, 11131389 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\n",
      "image 1/1 /home/mangguai/capstone/data/greenlight.jpg: 416x640 1 biker, 2 pedestrians, 92.6ms\n",
      "Speed: 3.1ms preprocess, 92.6ms inference, 99.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "#before running this command, make sure you are in the correct directory, check with pwd\n",
    "!yolo task=detect mode=predict model=/home/mangguai/capstone/code/runs/detect/train5/weights/best.pt conf=0.25 source=/home/mangguai/capstone/data/greenlight.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

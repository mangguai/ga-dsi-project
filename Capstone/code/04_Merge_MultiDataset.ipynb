{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone Project - TheiaVision: Object Detection Technology for PMD Safety Alerts\n",
    "\n",
    "> Authors: Ng Wei\n",
    "---\n",
    "\n",
    "**Problem Statement:**  \n",
    "How can we enhance the safety of Personal Mobility Devices (PMDs) in urban environments by using object detection to improve PMD users' ability to perceive and respond to their surroundings?\n",
    "\n",
    "**Target Audience:**\n",
    "Management Team of PMD Maker\n",
    "\n",
    "**Summary:**\n",
    "This project aims to develop a object detection system to identifies obstacles such as pedestrians, vehicles, and traffic signs. By leveraging CNN algorithms YOLO model, this system would help Darren, a project manager, to lead the development of an alert system with object detection technology\n",
    "\n",
    "There are a total of three notebooks for this project:  \n",
    " 1. `01_EDA.ipynb`   \n",
    " 2. `02_Modelling_Pytorch_SimpleCNN_SGTrafficSign.ipynb`   \n",
    " 3. `03_Modelling_YOLOv8_labeled_SGTrafficSign.ipynb`\n",
    " 4. `04_Merge_MultiDataset.ipynb`\n",
    " 5. `05_Modelling_YOLOv8_combined_data.ipynb`\n",
    " 6. `06_YOLOv8_Hyperparameter_Tuning.ipynb`\n",
    "\n",
    "---\n",
    "**This Notebook**\n",
    "- We will get the additional dataset from Udacity and merge with labeled Singapore Traffic Sign dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Download Udacity Self Driving Car Dataset after labeled on Roboflow\n",
    "This section of the code is responsible for importing the necessary libraries that will be used in the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1 Download additional dataset from Roboflow to merge with exisiting training dataset.\n",
    "The public dataset link: [Roboflow](https://public.roboflow.com/object-detection/self-driving-car/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"Uf5F9mzBsL27ozIYiWvW\")\n",
    "project = rf.workspace(\"roboflow-gw7yv\").project(\"self-driving-car\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2 Merge two data into Capstone/code as `Master_Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Modity label files in `Master_Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are merging Udacity dataset into Traffic Sign dataset. However, the label have similar classes. We need to change the labels.\n",
    "- Since traffic sign dataset have 7 classes (class 0 to 6), we need to change the Udacity classes starting from class 7 (class 0 --> class 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1 Modify label files for Udacity dataset by increment the class number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def adjust_label_indices(label_dir, adjustment):\n",
    "    for label_file in os.listdir(label_dir):\n",
    "        path = os.path.join(label_dir, label_file)\n",
    "        with open(path, 'r+') as file:\n",
    "            lines = file.readlines()\n",
    "            file.seek(0)\n",
    "            file.truncate()  # Clear existing content\n",
    "            for line in lines:\n",
    "                parts = line.split()\n",
    "                parts[0] = str(int(parts[0]) + adjustment)  # Adjust the class index\n",
    "                file.write(\" \".join(parts) + \"\\n\")\n",
    "\n",
    "# Adjust labels for the self-driving car dataset (class indices start at 7)\n",
    "adjust_label_indices('/home/mangguai/capstone/code/Master_Dataset/export/labels', 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `count_classes` function reads label files from a specified directory to count the occurrences of each class index. It uses a `defaultdict` from Python's `collections` module for storing and updating these counts. Each label file is read line-by-line, extracting the class index, which is then incremented in the dictionary. The function returns a dictionary with the total counts of each class index and is demonstrated with an example that prints these counts and the number of unique classes detected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_classes(label_dir):\n",
    "    class_counts = defaultdict(int)  # Dictionary to store counts of each class index\n",
    "    \n",
    "    for label_file in os.listdir(label_dir):\n",
    "        path = os.path.join(label_dir, label_file)\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                class_index = line.split()[0]  # Get the class index from each line\n",
    "                class_counts[int(class_index)] += 1  # Increment count for this class\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "label_dir = '/home/mangguai/capstone/code/Master_Dataset/export/labels'\n",
    "class_counts = count_classes(label_dir)\n",
    "print(\"Class counts:\")\n",
    "for class_index in sorted(class_counts):\n",
    "    print(f\"Class {class_index}: {class_counts[class_index]} images\")\n",
    "print(\"Number of unique classes:\", len(class_counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_label_files_with_classes` function scans a specified directory for label files containing certain class indices, limiting the results to a maximum of five files per class. It employs a `defaultdict` from the `collections` module to organize the files by class index. The function reads each label file, extracts class indices from each line, and adds the file name to a list for the corresponding class if the class index falls within a user-defined range and the file hasn't been added previously. This method ensures that no more than five files are listed per class, providing a manageable dataset for analysis or machine learning model training. Example usage is provided to demonstrate how to call the function and print the files associated with each class index clearly, using new lines for readability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_label_files_with_classes(label_dir, class_range):\n",
    "    class_files = defaultdict(list)  # Dictionary to store lists of files for each class index\n",
    "\n",
    "    for label_file in os.listdir(label_dir):\n",
    "        path = os.path.join(label_dir, label_file)\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            found_classes = set()  # To avoid adding the same file multiple times for the same class\n",
    "            for line in lines:\n",
    "                class_index = int(line.split()[0])  # Get the class index from each line\n",
    "                if class_index in class_range and class_index not in found_classes:\n",
    "                    if len(class_files[class_index]) < 5:  # Ensure no more than 5 files are stored\n",
    "                        class_files[class_index].append(label_file)\n",
    "                    found_classes.add(class_index)\n",
    "\n",
    "    return class_files\n",
    "\n",
    "# Define the class range you are interested in\n",
    "class_range = set(range(7, 18))  # From 7 to 17\n",
    "\n",
    "# Example usage\n",
    "label_dir = '/home/mangguai/capstone/code/Master_Dataset/export/labels'\n",
    "class_files = find_label_files_with_classes(label_dir, class_range)\n",
    "\n",
    "# Printing the results with newline for each file name\n",
    "for class_index in class_range:\n",
    "    if class_index in class_files:  # Check if there are any files for the class\n",
    "        files = \"\\n\".join(class_files[class_index])  # Join files with newline character\n",
    "        print(f\"Class {class_index} has the following label files:\\n{files}\\n\")\n",
    "    else:\n",
    "        print(f\"Class {class_index} has no label files.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.2 Merge Traffic Light Left into Traffic Light class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the need to consolidate traffic light classes with their \"left\" directional variants and to streamline class indices, the following mappings have been established:\n",
    "\n",
    "- **Biker (7)** remains as class 7.\n",
    "- **Car (8)** remains as class 8.\n",
    "- **Pedestrians (9)** remains as class 9.\n",
    "- **Traffic Light (10)** remains as class 10.\n",
    "- **Traffic Light-Green (11)** merges with **Traffic Light-GreenLeft (12)** to form the new class 11.\n",
    "- **Traffic Light-Red (13)** merges with **Traffic Light-RedLeft (14)** to form the new class 12.\n",
    "- **Traffic Light-Yellow (15)** merges with **Traffic Light-YellowLeft (16)** to form the new class 13.\n",
    "- **Truck (17)** is reassigned to class 14.\n",
    "\n",
    "This approach reduces the total number of classes by merging standard and \"left\" variations of traffic lights into single classes and renumbering the subsequent classes. Here is the updated class structure:\n",
    "\n",
    "- **7**: Biker\n",
    "- **8**: Car\n",
    "- **9**: Pedestrians\n",
    "- **10**: Traffic Light\n",
    "- **11**: Traffic Light-Green (merged with Traffic Light-GreenLeft)\n",
    "- **12**: Traffic Light-Red (merged with Traffic Light-RedLeft)\n",
    "- **13**: Traffic Light-Yellow (merged with Traffic Light-YellowLeft)\n",
    "- **14**: Truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def adjust_classes(label_dir, mapping):\n",
    "    for label_file in os.listdir(label_dir):\n",
    "        path = os.path.join(label_dir, label_file)\n",
    "        with open(path, 'r+') as file:\n",
    "            lines = file.readlines()\n",
    "            file.seek(0)\n",
    "            file.truncate()  # Clear the file\n",
    "            for line in lines:\n",
    "                parts = line.split()\n",
    "                class_index = int(parts[0])\n",
    "                if class_index in mapping:\n",
    "                    parts[0] = str(mapping[class_index])  # Update class index based on mapping\n",
    "                file.write(\" \".join(parts) + \"\\n\")\n",
    "\n",
    "# Define your class mapping\n",
    "mapping = {\n",
    "    7: 7,\n",
    "    8: 8,\n",
    "    9: 9,\n",
    "    10: 10,\n",
    "    11: 11,\n",
    "    12: 11,\n",
    "    13: 12,\n",
    "    14: 12,\n",
    "    15: 13,\n",
    "    16: 13,\n",
    "    17: 14\n",
    "}\n",
    "\n",
    "# Example usage\n",
    "label_dir = '/home/mangguai/capstone/code/Master_Dataset/export/labels'\n",
    "adjust_classes(label_dir, mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the accuracy of the redefined class indices and their corresponding mergers, a thorough review was conducted. This verification process confirms that the above implementation of merging directional variations of traffic lights into single classes and the reassignment of indices is correctly applied. Here’s the final class structure after verification:\n",
    "\n",
    "- **7**: Biker\n",
    "- **8**: Car\n",
    "- **9**: Pedestrians\n",
    "- **10**: Traffic Light\n",
    "- **11**: Traffic Light-Green (merged with Traffic Light-GreenLeft)\n",
    "- **12**: Traffic Light-Red (merged with Traffic Light-RedLeft)\n",
    "- **13**: Traffic Light-Yellow (merged with Traffic Light-YellowLeft)\n",
    "- **14**: Truck\n",
    "\n",
    "This confirmation ensures the implementation aligns with the intended design and functionality requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_classes(label_dir):\n",
    "    class_counts = defaultdict(int)  # Dictionary to store counts of each class index\n",
    "    \n",
    "    for label_file in os.listdir(label_dir):\n",
    "        path = os.path.join(label_dir, label_file)\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                class_index = line.split()[0]  # Get the class index from each line\n",
    "                class_counts[int(class_index)] += 1  # Increment count for this class\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "# Example usage\n",
    "label_dir = '/home/mangguai/capstone/code/Master_Dataset/export/labels'\n",
    "class_counts = count_classes(label_dir)\n",
    "print(\"Class counts:\")\n",
    "for class_index in sorted(class_counts):\n",
    "    print(f\"Class {class_index}: {class_counts[class_index]} images\")\n",
    "print(\"Number of unique classes:\", len(class_counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can modify the `data.yaml` with the new modified classes above.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Combining `Self Driving Car` images file into `Singapore Traffic Sign` Train/Test/Valid folders\n",
    "\n",
    "`Self Driving Car` image data under `export` folder, we need to merge into `Singapore Traffic Sign`'s train/test/valid folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.1 Dataset Splitting Summary\n",
    "\n",
    "#### 4.3.1.1 Objective\n",
    "To split the dataset into training (70%), validation (20%), and testing (10%) sets, prioritizing the representation of rarer classes to ensure even distribution across the splits.\n",
    "\n",
    "#### 4.3.1.2 Process Overview\n",
    "1. **Count Class Frequencies:** Calculate the frequency of each class appearing in the label files. This helps identify rare classes.\n",
    "2. **Assign Images to Splits Based on Rarity:** Sort images based on the rarity of classes they contain. This ensures that images containing rarer classes are prioritized in the distribution, helping to maintain class balance across training, validation, and testing sets.\n",
    "3. **Distribute Files:** Move images and their corresponding label files into the respective directories based on their assigned split.\n",
    "\n",
    "#### 4.3.1.3 Implementation Details\n",
    "- **Directories Involved:**\n",
    "  - Source Directory: `/home/mangguai/capstone/code/Master_Dataset/export`\n",
    "  - Target Directories:\n",
    "    - Training: `/home/mangguai/capstone/code/Master_Dataset/train`\n",
    "    - Validation: `/home/mangguai/capstone/code/Master_Dataset/valid`\n",
    "    - Testing: `/home/mangguai/capstone/code/Master_Dataset/test`\n",
    "- **File Management:** Ensure each image and its corresponding label file are moved together to maintain consistency between image data and annotations.\n",
    "\n",
    "#### 4.3.1.4 Considerations\n",
    "- **File Formats:** Adjust the script if your image or label files use formats other than .jpg for images or .txt for labels.\n",
    "- **Random Seed:** Set a random seed (e.g., 42) for reproducibility of the splits.\n",
    "- **Directory Checks:** Verify the existence of the target directories before running the script or incorporate directory creation logic within the script.\n",
    "\n",
    "#### 4.3.1.5 Execution\n",
    "Run the provided Python script to perform the split. Monitor the process to verify that files are appropriately distributed and that class distribution goals are met.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def count_classes(label_dir):\n",
    "    class_counts = defaultdict(int)\n",
    "    image_classes = defaultdict(set)\n",
    "    \n",
    "    for label_file in os.listdir(label_dir):\n",
    "        path = os.path.join(label_dir, label_file)\n",
    "        with open(path, 'r') as file:\n",
    "            for line in file:\n",
    "                class_index = line.split()[0]\n",
    "                class_counts[int(class_index)] += 1\n",
    "                image_classes[label_file].add(int(class_index))\n",
    "    return class_counts, image_classes\n",
    "\n",
    "def split_datasets(base_dir, output_dirs, split_ratio=(0.7, 0.2, 0.1)):\n",
    "    label_dir = os.path.join(base_dir, 'labels')\n",
    "    image_dir = os.path.join(base_dir, 'images')\n",
    "    \n",
    "    class_counts, image_classes = count_classes(label_dir)\n",
    "    \n",
    "    # Sort images by the rarity of their classes\n",
    "    sorted_images = sorted(image_classes.keys(), key=lambda x: min(class_counts[i] for i in image_classes[x]))\n",
    "    \n",
    "    # Split images into training, validation, and testing\n",
    "    train_val, test = train_test_split(sorted_images, test_size=split_ratio[2], random_state=42)\n",
    "    train, val = train_test_split(train_val, test_size=split_ratio[1] / (split_ratio[0] + split_ratio[1]), random_state=42)\n",
    "    \n",
    "    # Function to move files\n",
    "    def move_files(files, dest_dir):\n",
    "        for file_name in files:\n",
    "            # Move label file\n",
    "            shutil.move(os.path.join(label_dir, file_name), os.path.join(dest_dir, 'labels', file_name))\n",
    "            # Move corresponding image file\n",
    "            image_file_name = file_name.replace('.txt', '.jpg')  # Assuming image files are .jpg\n",
    "            shutil.move(os.path.join(image_dir, image_file_name), os.path.join(dest_dir, 'images', image_file_name))\n",
    "    \n",
    "    # Move files to respective directories\n",
    "    move_files(train, os.path.join(output_dirs['train']))\n",
    "    move_files(val, os.path.join(output_dirs['valid']))\n",
    "    move_files(test, os.path.join(output_dirs['test']))\n",
    "\n",
    "# Example usage\n",
    "base_dir = '/home/mangguai/capstone/code/Master_Dataset/export'\n",
    "output_dirs = {\n",
    "    'train': '/home/mangguai/capstone/code/Master_Dataset/train',\n",
    "    'valid': '/home/mangguai/capstone/code/Master_Dataset/valid',\n",
    "    'test': '/home/mangguai/capstone/code/Master_Dataset/test'\n",
    "}\n",
    "split_datasets(base_dir, output_dirs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the total dataset, **3500 images** were identified as having no associated labels. These images are considered \"leftover\" as they cannot be directly used in supervised machine learning tasks which require labeled data for training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
